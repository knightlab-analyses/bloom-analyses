{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of blooming bacteria on Bray-Curtis distance\n",
    "### Supplementary figure 1\n",
    "\n",
    "In this Notebook, we test the effect of removing bloom sequences and the impact in beta diversity as measured by Bray Curtis distance. To do so, we're going to compare samples from four studies, the American Gut Project (AGP; Qiita ID [10317](https://qiita.ucsd.edu/study/description/10317)), the Personal Genome Project microbiome samples (PGP; Qiita ID [1189](https://qiita.ucsd.edu/study/description/1189)), the Human Genetics Shape the Gut Microbiome dataset (Twins UK; Qiita ID [2014](https://qiita.ucsd.edu/study/description/2014)) and samples from a whole grain diet study (ERC; Qiita ID [1481](https://qiita.ucsd.edu/study/description/1481)).\n",
    "\n",
    "Samples in the AGP study are shipped at room temperature. The other three studies were fresh-frozen. Our expectation is that the filtering will reduce distances between the American Gut vs. fresh-frozen studies, while the distances between fresh-frozen studies will change comparably less. The expectation is based on the assumption that the blooms have a higher impact on the American Gut data stemming from room temperature shipping.\n",
    "\n",
    "Specifically, we:\n",
    "\n",
    "1. Load the study datasets\n",
    "2. For an increasing number of bloom sequences (starting with zero blooms, and sorted by decreasing severity):\n",
    "    1. Filter out the bloom sequences\n",
    "    2. Rarefy to 1000 sequences per sample\n",
    "    3. Randomly select 1000 samples from each study (with replacement)\n",
    "    4. Calculate the Bray-Curtis distance for:\n",
    "        - AGP vs. PGP\n",
    "        - AGP vs. Twins UK\n",
    "        - AGP vs. ERC\n",
    "        - Twins UK vs. PGP\n",
    "        - ERC vs. Twins UK\n",
    "        - ERC vs. PGP\n",
    "\n",
    "3. Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plots inside the notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# load modules used in the analysis\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import biom\n",
    "import pandas as pd\n",
    "import skbio\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.stats.ordination import pcoa\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from emperor import Emperor, nbinstall\n",
    "\n",
    "nbinstall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sniff_category(metadata_path):\n",
    "    \"\"\"Determine which category describes fecal\n",
    "    \n",
    "    The metadata are not 100% consistent on category and value used\n",
    "    to describe a fecal sample.\n",
    "    \"\"\"\n",
    "    sniff = open(metadata_path).read().strip().split('\\t')\n",
    "    if 'ENV_MATTER' in sniff:\n",
    "        key = 'ENV_MATTER'\n",
    "        value = 'ENVO:feces'\n",
    "    elif 'env_matter' in sniff:\n",
    "        key = 'env_matter'\n",
    "        value = 'ENVO:feces'\n",
    "    elif 'env_material' in sniff:\n",
    "        key = 'env_material'\n",
    "        value = 'feces'\n",
    "    else:\n",
    "        raise KeyError(\"No interpretable column for denoting fecal\")\n",
    "        \n",
    "    return key, value\n",
    "\n",
    "\n",
    "def load(table_path, metadata_path, study_acronym):\n",
    "    \"\"\"Load a study, filter to fecal, drop samples with < 1000 reads\"\"\"\n",
    "    key, value = sniff_category(metadata_path)\n",
    "    \n",
    "    # load the biom table and remove any sample that does not contain reads\n",
    "    table = biom.load_table(table_path)\n",
    "    table.filter(lambda v, i, md: v.sum() > 0)  # drop samples without data\n",
    "    \n",
    "    # load metadata, set the index to the samples\n",
    "    metadata = pd.read_csv(metadata_path, sep='\\t', dtype=object, usecols=['#SampleID', key])\n",
    "    metadata.set_index('#SampleID', inplace=True)\n",
    "   \n",
    "    # verify we have information about all samples\n",
    "    assert set(table.ids()).issubset(metadata.index)\n",
    "    \n",
    "    # reduce to the fecal subset\n",
    "    fecal_metadata = metadata[metadata[key] == value]\n",
    "    fecal_metadata = fecal_metadata.loc[set(fecal_metadata.index) & set(table.ids())]\n",
    "    \n",
    "    # subset to fecal, keep samples with >= 1000 reads, and remove any empty OTUs\n",
    "    table.filter(fecal_metadata.index)\n",
    "    table.filter(lambda v, i, md: v.sum() >= 1000)\n",
    "    table.filter(lambda v, i, md: v.sum() > 0, axis='observation')\n",
    "    \n",
    "    # reduce the metadata to only the samples represented\n",
    "    fecal_metadata = fecal_metadata.loc[table.ids()]\n",
    "    \n",
    "    # normalize metadata (we already filtered to fecal based on study specific values)\n",
    "    fecal_metadata.columns = ['ENV_MATTER']\n",
    "    fecal_metadata['ENV_MATTER'] = 'feces'\n",
    "    fecal_metadata['study_acronym'] = study_acronym\n",
    "    \n",
    "    print(\"Fecal samples: %d\" % len(table.ids()))\n",
    "    \n",
    "    return table, fecal_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ag_table, ag_metadata       = load('../data/ag.qiita-10317.biom',   '../data/ag.qiita-10317.txt', 'AGP')\n",
    "twins_table, twins_metadata = load('../data/twins.qiita-2014.biom', '../data/twins.qiita-2014.txt', 'Twins')\n",
    "pgp_table, pgp_metadata     = load('../data/pgp.qiita-1189.biom',   '../data/pgp.qiita-1189.txt', 'PGP')\n",
    "erc_table, erc_metadata     = load('../data/erc.qiita-1481.biom',   '../data/erc.qiita-1481.txt', 'ERC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Join all data into a single table and data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = pgp_table.merge(erc_table).merge(twins_table).merge(ag_table)\n",
    "metadata = pd.concat([pgp_metadata, erc_metadata, twins_metadata, ag_metadata])\n",
    "\n",
    "assert set(table.ids()) == set(metadata.index)\n",
    "\n",
    "print(\"Total number of sOTUs: %d\\nTotal number of samples: %d\" % table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean Bray-Curtis distance for filtering levels\n",
    "\n",
    "Remove incrementally more blooms, starting from the most severe to least severe, and at each increment, compute the Bray Curtis distance between random sets of samples within each study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_and_remap(df, iterations, index, tag):\n",
    "    \"\"\"Sample with replacement from df, return the observed index positions\"\"\"\n",
    "    # determine what IDs are still in the table\n",
    "    valid = set(index).intersection(df.index)\n",
    "    \n",
    "    # randomly sample with replacement over the IDs\n",
    "    ids = df.loc[valid].sample(iterations, replace=True).index.values\n",
    "    \n",
    "    # determine their index position in the matrix\n",
    "    indices = [index[i] for i in ids]\n",
    "    \n",
    "    if len(df) - len(valid):\n",
    "        print(\"  %s - %d sample(s) did not pass filtering\" % (tag, len(df) - len(valid)))\n",
    "\n",
    "    return indices \n",
    "\n",
    "# initial conditions\n",
    "iterations = 1000\n",
    "sequences = list(skbio.read('../data/newbloom.all.fna', format='fasta'))\n",
    "\n",
    "# datasets to store the resulting bray curtis distances\n",
    "ag_vs_twin  = np.zeros((len(sequences) + 1, iterations))\n",
    "ag_vs_pgp   = np.zeros((len(sequences) + 1, iterations))\n",
    "ag_vs_erc   = np.zeros((len(sequences) + 1, iterations))\n",
    "pgp_vs_twin = np.zeros((len(sequences) + 1, iterations))\n",
    "erc_vs_twin = np.zeros((len(sequences) + 1, iterations))\n",
    "erc_vs_pgp  = np.zeros((len(sequences) + 1, iterations))\n",
    "\n",
    "blooms = set()\n",
    "for bloom_idx in range(len(sequences) + 1):\n",
    "    # make sure we run once without any blooms\n",
    "    if bloom_idx > 0:\n",
    "        blooms.add(str(sequences[bloom_idx - 1]))\n",
    "        \n",
    "    print(\"Operating on %d bloom(s)...\" % len(blooms))\n",
    "    \n",
    "    # remove bloom sequences, rarefy, normalize to [0, 1], and fetch a dense representation\n",
    "    table_wo_blooms = table.filter(blooms, invert=True, inplace=False, axis='observation')\n",
    "    table_wo_blooms = table_wo_blooms.subsample(1000).norm()\n",
    "    table_wo_blooms_mat = table_wo_blooms.matrix_data.T.toarray()\n",
    "    \n",
    "    # compute an index mapping each ID to a row in the matrix\n",
    "    index = {i: idx for idx, i in enumerate(table_wo_blooms.ids())}\n",
    "    \n",
    "    # get a bunch of random positions in the matrix for each study\n",
    "    ag_samples    = sample_and_remap(ag_metadata, iterations, index, 'AG') \n",
    "    pgp_samples   = sample_and_remap(pgp_metadata, iterations, index, 'PGP')\n",
    "    erc_samples   = sample_and_remap(erc_metadata, iterations, index, 'ERC')\n",
    "    twins_samples = sample_and_remap(twins_metadata, iterations, index, 'Twins')\n",
    "    \n",
    "    # pull out the matrix of counts corresponding to the random positions\n",
    "    ag_counts    = table_wo_blooms_mat[ag_samples]\n",
    "    pgp_counts   = table_wo_blooms_mat[pgp_samples]\n",
    "    erc_counts   = table_wo_blooms_mat[erc_samples]\n",
    "    twins_counts = table_wo_blooms_mat[twins_samples]\n",
    "    \n",
    "    # compute bray curtis\n",
    "    ag_vs_twin[bloom_idx]  = np.array([braycurtis(u, v) for u, v in zip(ag_counts, twins_counts)])\n",
    "    ag_vs_pgp[bloom_idx]   = np.array([braycurtis(u, v) for u, v in zip(ag_counts, pgp_counts)])\n",
    "    ag_vs_erc[bloom_idx]   = np.array([braycurtis(u, v) for u, v in zip(ag_counts, erc_counts)])\n",
    "    pgp_vs_twin[bloom_idx] = np.array([braycurtis(u, v) for u, v in zip(pgp_counts, twins_counts)])\n",
    "    erc_vs_twin[bloom_idx] = np.array([braycurtis(u, v) for u, v in zip(erc_counts, twins_counts)])\n",
    "    erc_vs_pgp[bloom_idx]  = np.array([braycurtis(u, v) for u, v in zip(erc_counts, pgp_counts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_comparison(results, color, against_ag):\n",
    "    \"\"\"Plot mean and stderr for the values in results\"\"\"\n",
    "    n_blooms, iterations = results.shape\n",
    "    x_axis = np.arange(n_blooms)\n",
    "    \n",
    "    results_mean = results.mean(axis=1)\n",
    "    results_stderr = results.std(axis=1) / np.sqrt(iterations)\n",
    "    \n",
    "    plt.fill_between(x_axis, \n",
    "                     results_mean + results_stderr, \n",
    "                     results_mean - results_stderr, \n",
    "                     alpha=0.25, color=color)\n",
    "    \n",
    "    linestyle = '-' if against_ag else '--'\n",
    "    plt.plot(x_axis, results_mean, color=color, lw=2, linestyle=linestyle)\n",
    "\n",
    "plt.figure()\n",
    "plot_comparison(ag_vs_twin, 'r', True)\n",
    "plot_comparison(ag_vs_pgp, 'b', True)\n",
    "plot_comparison(ag_vs_erc, 'y', True)\n",
    "plot_comparison(pgp_vs_twin, 'g', False)\n",
    "plot_comparison(erc_vs_twin, 'k', False)\n",
    "plot_comparison(erc_vs_pgp, 'c', False)\n",
    "\n",
    "plt.legend(['AG - UK Twins',\n",
    "            'AG - PGP',\n",
    "            'AG - ERC',\n",
    "            'PGP - UK Twins',\n",
    "            'ERC - UK Twins',\n",
    "            'ERC - PGP'], loc='center right')\n",
    "plt.xlabel('Number of candidate blooming bacteria', fontsize=15)\n",
    "plt.ylabel('Mean Bray-Curtis distance', fontsize=15)\n",
    "plt.xlim(0, len(ag_vs_twin) - 1)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compare in principal coordinates space\n",
    "\n",
    "Next, we're going to produce principal coordinates plots highlighting the difference in beta diversity (via Bray Curtis) prior to and following the removal of blooms. For this set of figures, we're going to randomly subsample the larger studies down to a smaller number of samples to avoid a heavy study bias. \n",
    "\n",
    "The subsequent plots which are displayed in the manuscript use these EMPeror plots, colored by \"study_acronym\", with the samples scaled by the \"bloom_counts\" key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_samples = 200\n",
    "top_n_blooms = 8\n",
    "blooms = [str(s) for s in sequences[:top_n_blooms]]\n",
    "\n",
    "ag_table_subset = ag_table.subsample(max_samples, by_id=True)\n",
    "twins_table_subset = twins_table.subsample(max_samples, by_id=True)\n",
    "pgp_table_subset = pgp_table.subsample(max_samples, by_id=True)\n",
    "erc_table_subset = erc_table.subsample(max_samples, by_id=True)\n",
    "\n",
    "with_bloom = pgp_table_subset.merge(erc_table_subset).merge(twins_table_subset).merge(ag_table_subset)\n",
    "without_bloom = with_bloom.filter(set(blooms), axis='observation', inplace=False, invert=True)\n",
    "\n",
    "metadata_subset = metadata.loc[with_bloom.ids()].copy()\n",
    "metadata_subset['bloom_counts'] = (with_bloom.sum(axis='sample') - without_bloom.sum(axis='sample')).astype(int)\n",
    "\n",
    "with_bloom = with_bloom.subsample(1000)\n",
    "without_bloom = without_bloom.subsample(1000)\n",
    "\n",
    "with_bloom_counts = with_bloom.matrix_data.T.astype(int).toarray()\n",
    "without_bloom_counts = without_bloom.matrix_data.T.astype(int).toarray()\n",
    "\n",
    "with_bloom_dm = beta_diversity('braycurtis', with_bloom_counts, with_bloom.ids(), validate=False)\n",
    "with_bloom_pcoa = pcoa(with_bloom_dm)\n",
    "\n",
    "without_bloom_dm = beta_diversity('braycurtis', without_bloom_counts, without_bloom.ids(), validate=False)\n",
    "without_bloom_pcoa = pcoa(without_bloom_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Emperor(with_bloom_pcoa, metadata_subset, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Emperor(without_bloom_pcoa, metadata_subset, remote=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
